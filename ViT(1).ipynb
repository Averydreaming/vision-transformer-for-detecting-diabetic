{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJGxdyoiAEqX"
   },
   "source": [
    "1. 定义一个数据集的Class, 制作一个dataloader\n",
    "2. 建立ViT模型\n",
    "3. 数据预处理（随机旋转，随机缩放，随机扭曲）\n",
    "4. 划分训练集和验证集\n",
    "5. 定义模型，定义损失函数和优化器\n",
    "6. 训练模型\n",
    "7. 将训练好的模型放在测试集和验证集上进行预测\n",
    "8. 将结果保存并可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gas-NmJKDeul",
    "outputId": "686b0dbf-ddb2-4b83-ccda-3f7cb8a37a99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (0.9.2)\n",
      "Requirement already satisfied: torch>=1.7 in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from timm) (2.0.0)\n",
      "Requirement already satisfied: torchvision in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from timm) (0.15.1a0+60a3e72)\n",
      "Requirement already satisfied: pyyaml in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from timm) (6.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from timm) (0.14.1)\n",
      "Requirement already satisfied: safetensors in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from timm) (0.3.1)\n",
      "Requirement already satisfied: filelock in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from torch>=1.7->timm) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from torch>=1.7->timm) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from torch>=1.7->timm) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from torch>=1.7->timm) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from torch>=1.7->timm) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from huggingface-hub->timm) (2023.5.0)\n",
      "Requirement already satisfied: requests in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from huggingface-hub->timm) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from huggingface-hub->timm) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from huggingface-hub->timm) (23.1)\n",
      "Requirement already satisfied: numpy in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from torchvision->timm) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from torchvision->timm) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/zzrh/miniconda3/envs/MLhomework/lib/python3.11/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6zQggEEND8OA"
   },
   "outputs": [],
   "source": [
    "#!cd /content/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "False\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())     \u001b[38;5;66;03m# True\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 查看GPU数量，索引号从0开始\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)   \u001b[38;5;66;03m# 0\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 根据索引号查看GPU名字\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;66;03m# NVIDIA GeForce GTX 1070\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/MLhomework/lib/python3.11/site-packages/torch/cuda/__init__.py:674\u001b[0m, in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    673\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[0;32m~/miniconda3/envs/MLhomework/lib/python3.11/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 查看 pytorch 版本\n",
    "print(torch.__version__)             \n",
    "# 查看 GPU 是否可用\n",
    "print(torch.cuda.is_available())     # True\n",
    "# 查看GPU数量，索引号从0开始\n",
    "print(torch.cuda.current_device())   # 0\n",
    "# 根据索引号查看GPU名字\n",
    "print(torch.cuda.get_device_name(0)) # NVIDIA GeForce GTX 1070\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_dkFir8Nj0s"
   },
   "source": [
    "需要安装pytorch，timm和torchvision，然后可以使用预训练的Vision Transformer模型。在这个例子中，我将使用timm库，它包含了许多预训练模型，包括Vision Transformer。也需要安装Pandas来处理数据集，以及使用PIL来处理图像。\n",
    "\n",
    "我将使用预训练的Vision Transformer（ViT）进行迁移学习，而且在训练模型时，我将为错误诊断有疾病的人分配更高的权重，以尽量避免出现这种情况。这种方法被称为成本敏感的学习\n",
    "\n",
    "我的医学数据集涉及到了一种称为\"类别不平衡\"的常见问题，特别是在医学图像处理中，更倾向于避免假阴性（将疾病分类为无疾病）而不是假阳性（将无疾病分类为有疾病）。可以通过为每个类别分配不同的权重来修改损失函数，使模型更倾向于正确分类疾病类别。\n",
    "\n",
    "下面是一个例子，我将对疾病类别（1-4）分配更高的权重：\n",
    "\n",
    "\n",
    "```\n",
    "# 指定每个类别的权重，增大疾病类别的权重\n",
    "weights = [0.5, 2.0, 2.0, 2.0, 2.0]\n",
    "class_weights = torch.FloatTensor(weights).to(device)\n",
    "\n",
    "# 使用加权交叉熵损失\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "```\n",
    "\n",
    "这将使得模型在错误分类疾病类别时受到更大的惩罚，因此模型更倾向于将图像分类为疾病类别，而不是无疾病类别。\n",
    "\n",
    "注意，这种方法可能会导致更多的假阳性错误，因为模型可能会过于慎重，将一些无疾病的图像错误地分类为有疾病。因此，我们可能需要对这些权重进行调整，以找到正确分类和避免假阴性之间的最佳平衡。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whK-6dE2IAvz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 设定超参数\n",
    "batch_size = 32\n",
    "num_epochs = 60\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据集类\n",
    "class APTOSDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None, has_labels=True):\n",
    "        self.labels_frame = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.has_labels = has_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.labels_frame.iloc[idx, 0]\n",
    "        image = Image.open(f\"{self.root_dir}/{img_name}.png\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.has_labels:\n",
    "          label = self.labels_frame.iloc[idx, 1]\n",
    "          return image, label\n",
    "        else:\n",
    "          return image, _\n",
    "\n",
    "# Vision Transformer模型类\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VisionTransformer, self).__init__()\n",
    "        self.model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "        num_ftrs = self.model.head.in_features\n",
    "        self.model.head = nn.Linear(num_ftrs, 5)  # 目标类别数为5\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "# 数据预处理\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=30),  # 随机旋转角度在 -30 到 30 度之间\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.9, 1.1)),  # 随机缩放在 0.9 到 1.1 之间，然后随机裁剪到 224x224 大小\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), shear=0.2),  # 随机扭曲，并将图像平移 x 和 y 方向的比例在 0.2 以内\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_csv_root = './train.csv'\n",
    "test_csv_root = './test.csv'\n",
    "train_img_root = './train_images'\n",
    "test_img_root = './test_images'\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_labels_frame = pd.read_csv(train_csv_root)\n",
    "train_df, val_df = train_test_split(train_labels_frame, test_size=0.1)\n",
    "\n",
    "# 数据集和数据加载器\n",
    "train_dataset = APTOSDataset(dataframe=train_df, root_dir=train_img_root, transform=transform)\n",
    "val_dataset = APTOSDataset(dataframe=val_df, root_dir=train_img_root, transform=test_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 模型、损失函数和优化器\n",
    "model = VisionTransformer().to(device)\n",
    "\n",
    "# 指定每个类别的权重，增大疾病类别的权重\n",
    "weights = [0.5, 2.0, 2.0, 2.0, 2.0]\n",
    "class_weights = torch.FloatTensor(weights).to(device)\n",
    "# 使用加权交叉熵损失\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 训练模型\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    train_correct = 0\n",
    "    val_correct = 0\n",
    "\n",
    "    start_time = time.time()  # 记录一个epoch的程序开始时间\n",
    "    # print(f\"epoch {epoch} training!\")\n",
    "    model.train()\n",
    "    # for images, labels in train_loader:\n",
    "    for images, labels in tqdm(train_loader, desc='train'):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()  # 把模型的梯度清0\n",
    "        loss.backward() # 损失反向传播计算新的梯度\n",
    "        optimizer.step() # 用上一步计算的新梯度来更新网络的权重\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # print(f\"epoch {epoch} valid!\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # for images, labels in val_loader:\n",
    "        for images, labels in tqdm(val_loader, desc='valid'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    val_loss = val_loss/len(val_loader.sampler)\n",
    "    train_accuracy = train_correct / len(train_loader.sampler)\n",
    "    val_accuracy = val_correct / len(val_loader.sampler)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "\n",
    "    end_time = time.time()  # 记录程序结束时间\n",
    "    run_time = end_time - start_time  # 计算程序运行时间，单位为秒\n",
    "\n",
    "    print(f'Epoch: {epoch+1} \\t running time: {run_time:.2f} s \\t Training Loss: {train_loss:.6f} \\tValidation Loss: {val_loss:.6f} \\tTraining Accuracy: {train_accuracy:.6f} \\tValidation Accuracy: {val_accuracy:.6f}')\n",
    "    if (epoch+1)%20==0:\n",
    "      torch.save(model.state_dict(), f'model_weights_epoch{epoch+1}.pth')\n",
    "\n",
    "\n",
    "# 绘制损失曲线和准确率曲线\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.plot(train_losses, label='Training loss')\n",
    "ax1.plot(val_losses, label='Validation loss')\n",
    "ax1.legend(frameon=False)\n",
    "ax1.set_title(\"Loss curves\")\n",
    "\n",
    "ax2.plot(train_accuracies, label='Training accuracy')\n",
    "ax2.plot(val_accuracies, label='Validation accuracy')\n",
    "ax2.legend(frameon=False)\n",
    "ax2.set_title(\"Accuracy curves\")\n",
    "\n",
    "# 保存图像到文件\n",
    "plt.savefig('loss_and_accuracy_curves.png', dpi=300)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxrXgVNjO9Qk"
   },
   "source": [
    "## 保存测试集的预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgatcJAWJKCc"
   },
   "outputs": [],
   "source": [
    "# 保存测试集的预测结果\n",
    "test_labels_frame = pd.read_csv(test_csv_root)\n",
    "\n",
    "test_dataset = APTOSDataset(dataframe=test_labels_frame, root_dir=test_img_root, transform=test_transform, has_labels=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    # for images, _ in test_loader:\n",
    "    for images, labels in tqdm(test_loader, desc='test'):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 保存预测结果到csv文件\n",
    "submission = pd.DataFrame({'id_code': test_dataset.labels_frame['id_code'], 'diagnosis': predictions})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
